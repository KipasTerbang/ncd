{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e405366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.datasets import ImageFolder \n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from finch import FINCH\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    \n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    acc = w[row_ind, col_ind].sum() / y_pred.size\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\nEpoch {epoch+1} | Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Extracting features\"):\n",
    "            images = images.to(device)\n",
    "            feat = model(images)\n",
    "            print(\"Output shape:\", feat.shape)\n",
    "            features.append(feat.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "results = []\n",
    "all_image_info = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c434e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(5):\n",
    "    labeled_transform = transforms.Compose([\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "    labeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\32labeled_20unlabeled\\labeled\"\n",
    "\n",
    "    labeled_dataset = ImageFolder(root=labeled_folder, \n",
    "    transform=labeled_transform) \n",
    "    print(f\"Total gambar dalam labeled dataset: {len(labeled_dataset)} {len(labeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True) \n",
    "    print(f\"Total loader gambar dalam labeled dataset: {len(labeled_loader)}\")\n",
    "    \n",
    "    model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    model.heads = torch.nn.Linear(model.heads.head.in_features, len(labeled_dataset.classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    print(model.encoder.layers[0].mlp[1])\n",
    "    \n",
    "    train_model(model, labeled_loader, epochs=5)\n",
    "\n",
    "    torch.save(model.state_dict(), \"vit_b16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gambar dalam unlabel dataset: 2000  20\n",
      "Total loader gambar dalam unlabel dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6428\\1686554962.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   1%|          | 1/125 [00:00<00:40,  3.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:22,  5.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:21,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:20,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:18,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:17,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:02<00:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:15,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:15,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:03<00:15,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:15,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:14,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:14,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:04<00:14,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:13,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:13,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:05<00:13,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:12,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:12,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:05<00:12,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:06<00:12,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:11,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:11,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:07<00:11,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:11,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:07<00:10,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:07<00:10,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:10,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:08<00:09,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:08<00:09,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:09<00:09,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:09,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:09<00:08,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:09<00:08,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:10<00:08,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:10<00:07,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:10<00:07,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:11<00:07,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:11<00:06,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:11<00:06,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:11<00:06,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:05,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:12<00:05,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:12<00:05,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:13<00:05,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:13<00:05,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:13<00:04,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:13<00:04,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:14<00:04,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:14<00:03,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:14<00:03,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:15<00:03,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:15<00:02,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:15<00:02,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:15<00:02,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:16<00:02,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:16<00:01,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:16<00:01,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:17<00:01,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:17<00:00,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:17<00:00,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:18<00:00,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 452 clusters\n",
      "Partition 1: 94 clusters\n",
      "Partition 2: 22 clusters\n",
      "Partition 3: 6 clusters\n",
      "Partition 4: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7375\n",
      "Normalized Mutual Information (NMI): 0.8360\n",
      "Number of clusters found: 22\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.6670\n",
      "Normalized Mutual Information (NMI): 0.7542\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabel dataset: 2000  20\n",
      "Total loader gambar dalam unlabel dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6428\\1686554962.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   0%|          | 0/125 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 2/125 [00:00<00:23,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   3%|▎         | 4/125 [00:00<00:20,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 6/125 [00:01<00:18,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▋         | 8/125 [00:01<00:17,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 10/125 [00:01<00:17,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|▉         | 12/125 [00:01<00:16,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 14/125 [00:02<00:16,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|█▎        | 16/125 [00:02<00:15,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 18/125 [00:02<00:15,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|█▌        | 20/125 [00:03<00:15,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 22/125 [00:03<00:15,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|█▉        | 24/125 [00:03<00:14,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 26/125 [00:03<00:14,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 28/125 [00:04<00:14,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▍       | 30/125 [00:04<00:13,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▌       | 32/125 [00:04<00:13,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 34/125 [00:05<00:13,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██▉       | 36/125 [00:05<00:12,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|███       | 38/125 [00:05<00:12,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  32%|███▏      | 40/125 [00:05<00:12,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▎      | 42/125 [00:06<00:12,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  35%|███▌      | 44/125 [00:06<00:11,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███▋      | 46/125 [00:06<00:11,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 48/125 [00:07<00:11,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|████      | 50/125 [00:07<00:10,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 52/125 [00:07<00:10,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|████▎     | 54/125 [00:07<00:10,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  45%|████▍     | 56/125 [00:08<00:09,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▋     | 58/125 [00:08<00:09,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  48%|████▊     | 60/125 [00:08<00:09,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|████▉     | 62/125 [00:09<00:08,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  51%|█████     | 64/125 [00:09<00:08,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  53%|█████▎    | 66/125 [00:09<00:08,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▍    | 68/125 [00:09<00:08,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|█████▌    | 70/125 [00:10<00:07,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 72/125 [00:10<00:07,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▉    | 74/125 [00:10<00:07,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  61%|██████    | 76/125 [00:11<00:06,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 78/125 [00:11<00:07,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  64%|██████▍   | 80/125 [00:11<00:06,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▌   | 82/125 [00:12<00:06,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  67%|██████▋   | 84/125 [00:12<00:05,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  69%|██████▉   | 86/125 [00:12<00:05,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|███████   | 88/125 [00:12<00:05,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  72%|███████▏  | 90/125 [00:13<00:05,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▎  | 92/125 [00:13<00:04,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|███████▌  | 94/125 [00:13<00:04,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  77%|███████▋  | 96/125 [00:13<00:04,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 98/125 [00:14<00:03,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  80%|████████  | 100/125 [00:14<00:03,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 102/125 [00:14<00:03,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  83%|████████▎ | 104/125 [00:15<00:02,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  85%|████████▍ | 106/125 [00:15<00:02,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▋ | 108/125 [00:15<00:02,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  88%|████████▊ | 110/125 [00:15<00:02,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|████████▉ | 112/125 [00:16<00:01,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  91%|█████████ | 114/125 [00:16<00:01,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  93%|█████████▎| 116/125 [00:16<00:01,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▍| 118/125 [00:17<00:01,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  96%|█████████▌| 120/125 [00:17<00:00,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 122/125 [00:17<00:00,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  99%|█████████▉| 124/125 [00:17<00:00,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 465 clusters\n",
      "Partition 1: 106 clusters\n",
      "Partition 2: 29 clusters\n",
      "Partition 3: 11 clusters\n",
      "Partition 4: 3 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.6765\n",
      "Normalized Mutual Information (NMI): 0.8078\n",
      "Number of clusters found: 29\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.7210\n",
      "Normalized Mutual Information (NMI): 0.7879\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabel dataset: 2000  20\n",
      "Total loader gambar dalam unlabel dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6428\\1686554962.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   1%|          | 1/125 [00:00<00:17,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:17,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:17,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:18,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:17,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:17,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:16,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:15,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:15,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:15,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:14,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:14,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:14,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:03<00:15,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:14,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:13,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:04<00:13,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:13,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:12,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:05<00:12,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:06<00:12,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:11,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:11,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:06<00:11,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:11,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:07<00:10,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:07<00:10,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:10,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:08<00:09,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:08<00:09,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:08<00:09,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:09,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:09<00:08,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:09<00:08,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:10<00:08,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:10<00:07,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:10<00:07,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:10<00:07,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:11<00:07,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:11<00:06,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:11<00:06,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:06,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:12<00:05,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:12<00:05,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:13<00:05,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:13<00:04,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:13<00:04,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:13<00:04,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:14<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:14<00:03,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:14<00:03,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:15<00:03,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:15<00:02,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:15<00:02,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:15<00:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:16<00:02,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:16<00:01,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:16<00:01,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:17<00:01,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:17<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:17<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:17<00:00,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 440 clusters\n",
      "Partition 1: 97 clusters\n",
      "Partition 2: 26 clusters\n",
      "Partition 3: 8 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7920\n",
      "Normalized Mutual Information (NMI): 0.8664\n",
      "Number of clusters found: 26\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.7020\n",
      "Normalized Mutual Information (NMI): 0.8074\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabel dataset: 2000  20\n",
      "Total loader gambar dalam unlabel dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6428\\1686554962.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   1%|          | 1/125 [00:00<00:17,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:18,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:17,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:17,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:17,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:16,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:16,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:15,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:15,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:15,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:15,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:14,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:03<00:14,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:14,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:13,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:04<00:13,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:13,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:12,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:05<00:12,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:06<00:12,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:12,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:11,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:06<00:11,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:11,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:07<00:10,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:07<00:10,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:10,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:08<00:09,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:08<00:09,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:08<00:09,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:09,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:09<00:08,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:09<00:08,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:10<00:08,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:10<00:07,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:10<00:07,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:11<00:07,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:11<00:07,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:11<00:06,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:11<00:06,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:06,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:12<00:05,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:12<00:05,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:13<00:05,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:13<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:13<00:04,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:13<00:04,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:14<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:14<00:03,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:14<00:03,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:15<00:03,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:15<00:02,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:15<00:02,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:16<00:02,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:16<00:02,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:16<00:01,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:16<00:01,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:17<00:01,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:17<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:17<00:00,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:18<00:00,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 437 clusters\n",
      "Partition 1: 89 clusters\n",
      "Partition 2: 23 clusters\n",
      "Partition 3: 5 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.8205\n",
      "Normalized Mutual Information (NMI): 0.8549\n",
      "Number of clusters found: 23\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.7385\n",
      "Normalized Mutual Information (NMI): 0.8045\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabel dataset: 2000  20\n",
      "Total loader gambar dalam unlabel dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_6428\\1686554962.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   1%|          | 1/125 [00:00<00:18,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:17,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:17,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:18,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:17,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:17,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:16,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:16,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:15,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:15,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:15,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:15,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:15,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:04<00:15,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:14,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:13,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:04<00:13,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:13,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:12,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:05<00:12,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:06<00:12,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:12,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:11,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:07<00:12,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:11,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:07<00:11,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:07<00:10,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:10,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:08<00:09,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:08<00:09,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:09<00:09,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:09,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:09<00:08,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:09<00:08,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:10<00:08,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:10<00:07,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:10<00:07,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:11<00:07,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:11<00:06,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:11<00:06,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:12<00:06,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:06,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:12<00:05,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:12<00:05,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:13<00:05,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:13<00:04,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:13<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:14<00:04,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:14<00:04,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:14<00:03,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:14<00:03,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:15<00:03,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:15<00:02,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:15<00:02,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:16<00:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:16<00:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:16<00:01,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:16<00:01,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:17<00:01,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:17<00:00,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:17<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:18<00:00,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 434 clusters\n",
      "Partition 1: 93 clusters\n",
      "Partition 2: 23 clusters\n",
      "Partition 3: 6 clusters\n",
      "Partition 4: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.6755\n",
      "Normalized Mutual Information (NMI): 0.7816\n",
      "Number of clusters found: 23\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.6685\n",
      "Normalized Mutual Information (NMI): 0.7494\n",
      "Number of clusters found: 20\n",
      "Results saved to clustering_results_vit_b_16_pretrained_32labeled_20unlabeled_FINCH_KMEANS.csv\n"
     ]
    }
   ],
   "source": [
    "for trial in range(5):\n",
    "\n",
    "    unlabeled_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "    unlabeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\32labeled_20unlabeled\\unlabeled\"\n",
    "\n",
    "    unlabeled_dataset = ImageFolder(root=unlabeled_folder, transform=unlabeled_transform) \n",
    "    print(f\"Total gambar dalam unlabeled dataset: {len(unlabeled_dataset)}  {len(unlabeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Total loader gambar dalam unlabeled dataset: {len(unlabeled_loader)}\")\n",
    "    \n",
    "    model = vit_b_16(weights=None)\n",
    "    model.heads = torch.nn.Identity()\n",
    "    model.load_state_dict(torch.load(\"vit_b_16_finetuned_32labeled_20unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    unlabeled_features, unlabeled_true_labels = extract_features(unlabeled_loader, model)\n",
    "    \n",
    "    c, num_clust, req_c = FINCH(unlabeled_features, use_ann_above_samples=1000, verbose=True)\n",
    "    finch_clusters = c[:,2]\n",
    "\n",
    "    finch_nmi = normalized_mutual_info_score(unlabeled_true_labels, finch_clusters)\n",
    "    finch_acc = clustering_accuracy(unlabeled_true_labels, finch_clusters)\n",
    "\n",
    "    print(f\"\\nFINCH Clustering Performance:\")\n",
    "    print(f\"Clustering Accuracy (ACC): {finch_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {finch_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(finch_clusters))}\")\n",
    "    \n",
    "    num_clusters = len(np.unique(unlabeled_true_labels))\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans_clusters = kmeans.fit_predict(unlabeled_features)\n",
    "\n",
    "    # ----- Evaluasi -----\n",
    "    kmeans_nmi = normalized_mutual_info_score(unlabeled_true_labels, kmeans_clusters)\n",
    "    kmeans_acc = clustering_accuracy(unlabeled_true_labels, kmeans_clusters)\n",
    "\n",
    "    print(f\"\\nK-Means Clustering Performance: {num_clusters} Clusters\")\n",
    "    print(f\"Clustering Accuracy (ACC): {kmeans_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {kmeans_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(kmeans_clusters))}\")\n",
    "    \n",
    "    # Simpan hasil trial ini\n",
    "    results.append({\n",
    "        'trial': trial,\n",
    "        'FINCH_ACC': finch_acc,\n",
    "        'FINCH_NMI': finch_nmi,\n",
    "        'FINCH_Num_Clusters': len(np.unique(finch_clusters)),\n",
    "        'KMeans_ACC': kmeans_acc,\n",
    "        'KMeans_NMI': kmeans_nmi,\n",
    "        'KMeans_Num_Clusters': len(np.unique(kmeans_clusters)),\n",
    "    })\n",
    "    \n",
    "    # Simpan hasil per gambar\n",
    "    for i in range(len(unlabeled_dataset)):\n",
    "        path, true_label = unlabeled_dataset.samples[i]\n",
    "        image_info = {\n",
    "            'trial': trial,\n",
    "            'image_path': path,\n",
    "            'true_label': true_label,\n",
    "            'finch_cluster': int(finch_clusters[i]),\n",
    "            'kmeans_cluster': int(kmeans_clusters[i])\n",
    "        }\n",
    "        all_image_info.append(image_info)\n",
    "\n",
    "    # Simpan file CSV per trial\n",
    "    df_trial_detail = pd.DataFrame(all_image_info[-len(unlabeled_dataset):])  # ambil data dari trial ini saja\n",
    "    df_trial_detail.to_csv(f'vit_b_16_finetuned_32labeled_20unlabeled_trial_{trial}_image_clustering.csv', index=False)\n",
    "\n",
    "# Konversi ke DataFrame dan simpan ke CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "mean_values = df_results.select_dtypes(include=np.number).mean()\n",
    "\n",
    "mean_row = pd.DataFrame({\n",
    "    'trial': ['Average'],\n",
    "    'FINCH_ACC': [mean_values['FINCH_ACC']],\n",
    "    'FINCH_NMI': [mean_values['FINCH_NMI']],\n",
    "    'FINCH_Num_Clusters': [mean_values['FINCH_Num_Clusters']],\n",
    "    'KMeans_ACC': [mean_values['KMeans_ACC']],\n",
    "    'KMeans_NMI': [mean_values['KMeans_NMI']],\n",
    "    'KMeans_Num_Clusters': [mean_values['KMeans_Num_Clusters']]\n",
    "})\n",
    "\n",
    "df_results = pd.concat([df_results, mean_row], ignore_index=True)\n",
    "\n",
    "df_results.to_csv('clustering_results_vit_b_16_finetuned_32labeled_20unlabeled_FINCH_KMEANS.csv', index=False)\n",
    "print(\"Results saved to clustering_results_vit_b_16_finetuned_32labeled_20unlabeled_FINCH_KMEANS.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
