{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e405366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.datasets import ImageFolder \n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from finch import FINCH\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    \n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    acc = w[row_ind, col_ind].sum() / y_pred.size\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\nEpoch {epoch+1} | Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Extracting features\"):\n",
    "            images = images.to(device)\n",
    "            feat = model(images)\n",
    "            print(\"Output shape:\", feat.shape)\n",
    "            features.append(feat.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "results = []\n",
    "all_image_info = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(5):\n",
    "    labeled_transform = transforms.Compose([\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "    labeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\42labeled_10unlabeled\\labeled\"\n",
    "\n",
    "    labeled_dataset = ImageFolder(root=labeled_folder, \n",
    "    transform=labeled_transform) \n",
    "    print(f\"Total gambar dalam labeled dataset: {len(labeled_dataset)} {len(labeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True) \n",
    "    print(f\"Total loader gambar dalam labeled dataset: {len(labeled_loader)}\")\n",
    "    \n",
    "    model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    model.heads = torch.nn.Linear(model.heads.head.in_features, len(labeled_dataset.classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    print(model.encoder.layers[0].mlp[1])\n",
    "    \n",
    "    train_model(model, labeled_loader, epochs=5)\n",
    "\n",
    "    torch.save(model.state_dict(), \"vit_b16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a3eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total gambar dalam unlabel dataset: 1000  10\n",
      "Total loader gambar dalam unlabel dataset: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22708\\3236084286.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   2%|▏         | 1/63 [00:00<00:22,  2.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 3/63 [00:00<00:11,  5.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 5/63 [00:00<00:09,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|▉         | 6/63 [00:01<00:11,  5.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|█▎        | 8/63 [00:01<00:09,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|█▌        | 10/63 [00:01<00:08,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|█▉        | 12/63 [00:02<00:07,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 14/63 [00:02<00:07,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▌       | 16/63 [00:02<00:06,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  29%|██▊       | 18/63 [00:02<00:06,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  32%|███▏      | 20/63 [00:03<00:06,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  35%|███▍      | 22/63 [00:03<00:06,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 24/63 [00:03<00:05,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████▏     | 26/63 [00:04<00:05,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 28/63 [00:04<00:05,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  48%|████▊     | 30/63 [00:04<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  51%|█████     | 32/63 [00:05<00:04,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▍    | 34/63 [00:05<00:04,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 36/63 [00:05<00:03,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 38/63 [00:05<00:03,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 40/63 [00:06<00:03,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  67%|██████▋   | 42/63 [00:06<00:03,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 44/63 [00:06<00:02,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 46/63 [00:07<00:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 48/63 [00:07<00:02,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 50/63 [00:07<00:01,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  83%|████████▎ | 52/63 [00:07<00:01,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 54/63 [00:08<00:01,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 56/63 [00:08<00:01,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 58/63 [00:08<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 60/63 [00:09<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 62/63 [00:09<00:00,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([8, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 63/63 [00:09<00:00,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partition 0: 221 clusters\n",
      "Partition 1: 51 clusters\n",
      "Partition 2: 13 clusters\n",
      "Partition 3: 7 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7750\n",
      "Normalized Mutual Information (NMI): 0.8506\n",
      "Number of clusters found: 13\n",
      "\n",
      "K-Means Clustering Performance: 10 Clusters\n",
      "Clustering Accuracy (ACC): 0.7500\n",
      "Normalized Mutual Information (NMI): 0.8053\n",
      "Number of clusters found: 10\n",
      "Total gambar dalam unlabel dataset: 1000  10\n",
      "Total loader gambar dalam unlabel dataset: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22708\\3236084286.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   2%|▏         | 1/63 [00:00<00:09,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 3/63 [00:00<00:08,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 5/63 [00:00<00:08,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 7/63 [00:01<00:08,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 9/63 [00:01<00:08,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 11/63 [00:01<00:07,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 13/63 [00:01<00:07,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▍       | 15/63 [00:02<00:06,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 17/63 [00:02<00:06,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|███       | 19/63 [00:02<00:06,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 21/63 [00:03<00:06,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███▋      | 23/63 [00:03<00:05,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|███▉      | 25/63 [00:03<00:05,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|████▎     | 27/63 [00:03<00:05,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 29/63 [00:04<00:05,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 31/63 [00:04<00:05,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 33/63 [00:04<00:04,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|█████▌    | 35/63 [00:05<00:04,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▊    | 37/63 [00:05<00:03,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 39/63 [00:05<00:03,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▌   | 41/63 [00:06<00:03,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 43/63 [00:06<00:02,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████▏  | 45/63 [00:06<00:02,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|███████▍  | 47/63 [00:06<00:02,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 49/63 [00:07<00:02,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 51/63 [00:07<00:01,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 53/63 [00:07<00:01,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 55/63 [00:08<00:01,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 57/63 [00:08<00:00,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 59/63 [00:08<00:00,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 61/63 [00:09<00:00,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 63/63 [00:09<00:00,  6.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 768])\n",
      "Partition 0: 228 clusters\n",
      "Partition 1: 51 clusters\n",
      "Partition 2: 18 clusters\n",
      "Partition 3: 7 clusters\n",
      "Partition 4: 3 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7440\n",
      "Normalized Mutual Information (NMI): 0.8514\n",
      "Number of clusters found: 18\n",
      "\n",
      "K-Means Clustering Performance: 10 Clusters\n",
      "Clustering Accuracy (ACC): 0.7070\n",
      "Normalized Mutual Information (NMI): 0.7447\n",
      "Number of clusters found: 10\n",
      "Total gambar dalam unlabel dataset: 1000  10\n",
      "Total loader gambar dalam unlabel dataset: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22708\\3236084286.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   2%|▏         | 1/63 [00:00<00:08,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 3/63 [00:00<00:08,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 5/63 [00:00<00:08,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 7/63 [00:01<00:08,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 9/63 [00:01<00:07,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 11/63 [00:01<00:07,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 13/63 [00:01<00:07,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▍       | 15/63 [00:02<00:07,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 17/63 [00:02<00:06,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|███       | 19/63 [00:02<00:06,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 21/63 [00:03<00:06,  6.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███▋      | 23/63 [00:03<00:05,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|███▉      | 25/63 [00:03<00:05,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|████▎     | 27/63 [00:03<00:05,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 29/63 [00:04<00:04,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 31/63 [00:04<00:04,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 33/63 [00:04<00:04,  6.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|█████▌    | 35/63 [00:05<00:04,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▊    | 37/63 [00:05<00:03,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 39/63 [00:05<00:03,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▌   | 41/63 [00:05<00:03,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 43/63 [00:06<00:03,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████▏  | 45/63 [00:06<00:02,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|███████▍  | 47/63 [00:06<00:02,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 49/63 [00:07<00:02,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 51/63 [00:07<00:01,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 53/63 [00:07<00:01,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 55/63 [00:08<00:01,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 57/63 [00:08<00:00,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 59/63 [00:08<00:00,  5.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 61/63 [00:09<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 63/63 [00:09<00:00,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 768])\n",
      "Partition 0: 229 clusters\n",
      "Partition 1: 49 clusters\n",
      "Partition 2: 10 clusters\n",
      "Partition 3: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7920\n",
      "Normalized Mutual Information (NMI): 0.8366\n",
      "Number of clusters found: 10\n",
      "\n",
      "K-Means Clustering Performance: 10 Clusters\n",
      "Clustering Accuracy (ACC): 0.7520\n",
      "Normalized Mutual Information (NMI): 0.7880\n",
      "Number of clusters found: 10\n",
      "Total gambar dalam unlabel dataset: 1000  10\n",
      "Total loader gambar dalam unlabel dataset: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22708\\3236084286.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   2%|▏         | 1/63 [00:00<00:09,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 3/63 [00:00<00:08,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 5/63 [00:00<00:08,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 7/63 [00:01<00:08,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 9/63 [00:01<00:08,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 11/63 [00:01<00:07,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 13/63 [00:01<00:07,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▍       | 15/63 [00:02<00:07,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 17/63 [00:02<00:07,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|███       | 19/63 [00:02<00:06,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 21/63 [00:03<00:06,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███▋      | 23/63 [00:03<00:05,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|███▉      | 25/63 [00:03<00:05,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|████▎     | 27/63 [00:04<00:05,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 29/63 [00:04<00:05,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 31/63 [00:04<00:04,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 33/63 [00:04<00:04,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|█████▌    | 35/63 [00:05<00:04,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▊    | 37/63 [00:05<00:03,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 39/63 [00:05<00:03,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▌   | 41/63 [00:06<00:03,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 43/63 [00:06<00:02,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████▏  | 45/63 [00:06<00:02,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|███████▍  | 47/63 [00:07<00:02,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 49/63 [00:07<00:02,  6.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 51/63 [00:07<00:01,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 53/63 [00:07<00:01,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 55/63 [00:08<00:01,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 57/63 [00:08<00:00,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 59/63 [00:08<00:00,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 61/63 [00:09<00:00,  6.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 63/63 [00:09<00:00,  6.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 768])\n",
      "Partition 0: 241 clusters\n",
      "Partition 1: 52 clusters\n",
      "Partition 2: 16 clusters\n",
      "Partition 3: 5 clusters\n",
      "Partition 4: 4 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7270\n",
      "Normalized Mutual Information (NMI): 0.8166\n",
      "Number of clusters found: 16\n",
      "\n",
      "K-Means Clustering Performance: 10 Clusters\n",
      "Clustering Accuracy (ACC): 0.7340\n",
      "Normalized Mutual Information (NMI): 0.7716\n",
      "Number of clusters found: 10\n",
      "Total gambar dalam unlabel dataset: 1000  10\n",
      "Total loader gambar dalam unlabel dataset: 63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_22708\\3236084286.py:19: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"vit_b_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
      "Extracting features:   2%|▏         | 1/63 [00:00<00:09,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 3/63 [00:00<00:08,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 5/63 [00:00<00:08,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 7/63 [00:01<00:08,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 9/63 [00:01<00:07,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 11/63 [00:01<00:07,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 13/63 [00:01<00:07,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  24%|██▍       | 15/63 [00:02<00:06,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  27%|██▋       | 17/63 [00:02<00:06,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|███       | 19/63 [00:02<00:06,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 21/63 [00:03<00:06,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  37%|███▋      | 23/63 [00:03<00:05,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  40%|███▉      | 25/63 [00:03<00:05,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  43%|████▎     | 27/63 [00:03<00:05,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 29/63 [00:04<00:04,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 31/63 [00:04<00:04,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 33/63 [00:04<00:04,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  56%|█████▌    | 35/63 [00:05<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  59%|█████▊    | 37/63 [00:05<00:03,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 39/63 [00:05<00:03,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▌   | 41/63 [00:06<00:03,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 43/63 [00:06<00:02,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████▏  | 45/63 [00:06<00:02,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  75%|███████▍  | 47/63 [00:06<00:02,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 49/63 [00:07<00:02,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 51/63 [00:07<00:01,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 53/63 [00:07<00:01,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 55/63 [00:08<00:01,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 57/63 [00:08<00:00,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 59/63 [00:08<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 61/63 [00:08<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 63/63 [00:09<00:00,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([8, 768])\n",
      "Partition 0: 241 clusters\n",
      "Partition 1: 56 clusters\n",
      "Partition 2: 19 clusters\n",
      "Partition 3: 7 clusters\n",
      "Partition 4: 3 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.6930\n",
      "Normalized Mutual Information (NMI): 0.8149\n",
      "Number of clusters found: 19\n",
      "\n",
      "K-Means Clustering Performance: 10 Clusters\n",
      "Clustering Accuracy (ACC): 0.7610\n",
      "Normalized Mutual Information (NMI): 0.8155\n",
      "Number of clusters found: 10\n",
      "Results saved to clustering_results_vit_b_16_pretrained_42labeled_10unlabeled_FINCH_KMEANS.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for trial in range(5):\n",
    "\n",
    "    unlabeled_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "    unlabeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\42labeled_10unlabeled\\unlabeled\"\n",
    "\n",
    "    unlabeled_dataset = ImageFolder(root=unlabeled_folder, transform=unlabeled_transform) \n",
    "    print(f\"Total gambar dalam unlabeled dataset: {len(unlabeled_dataset)}  {len(unlabeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Total loader gambar dalam unlabeled dataset: {len(unlabeled_loader)}\")\n",
    "    \n",
    "    model = vit_b_16(weights=None)\n",
    "    model.heads = torch.nn.Identity()\n",
    "    model.load_state_dict(torch.load(\"vit_b_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    unlabeled_features, unlabeled_true_labels = extract_features(unlabeled_loader, model)\n",
    "    \n",
    "    c, num_clust, req_c = FINCH(unlabeled_features, use_ann_above_samples=1000, verbose=True)\n",
    "    finch_clusters = c[:,2]\n",
    "\n",
    "    finch_nmi = normalized_mutual_info_score(unlabeled_true_labels, finch_clusters)\n",
    "    finch_acc = clustering_accuracy(unlabeled_true_labels, finch_clusters)\n",
    "\n",
    "    print(f\"\\nFINCH Clustering Performance:\")\n",
    "    print(f\"Clustering Accuracy (ACC): {finch_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {finch_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(finch_clusters))}\")\n",
    "    \n",
    "    num_clusters = len(np.unique(unlabeled_true_labels))\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans_clusters = kmeans.fit_predict(unlabeled_features)\n",
    "\n",
    "    # ----- Evaluasi -----\n",
    "    kmeans_nmi = normalized_mutual_info_score(unlabeled_true_labels, kmeans_clusters)\n",
    "    kmeans_acc = clustering_accuracy(unlabeled_true_labels, kmeans_clusters)\n",
    "\n",
    "    print(f\"\\nK-Means Clustering Performance: {num_clusters} Clusters\")\n",
    "    print(f\"Clustering Accuracy (ACC): {kmeans_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {kmeans_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(kmeans_clusters))}\")\n",
    "    \n",
    "    # Simpan hasil trial ini\n",
    "    results.append({\n",
    "        'trial': trial,\n",
    "        'FINCH_ACC': finch_acc,\n",
    "        'FINCH_NMI': finch_nmi,\n",
    "        'FINCH_Num_Clusters': len(np.unique(finch_clusters)),\n",
    "        'KMeans_ACC': kmeans_acc,\n",
    "        'KMeans_NMI': kmeans_nmi,\n",
    "        'KMeans_Num_Clusters': len(np.unique(kmeans_clusters)),\n",
    "    })\n",
    "    \n",
    "    # Simpan hasil per gambar\n",
    "    for i in range(len(unlabeled_dataset)):\n",
    "        path, true_label = unlabeled_dataset.samples[i]\n",
    "        image_info = {\n",
    "            'trial': trial,\n",
    "            'image_path': path,\n",
    "            'true_label': true_label,\n",
    "            'finch_cluster': int(finch_clusters[i]),\n",
    "            'kmeans_cluster': int(kmeans_clusters[i])\n",
    "        }\n",
    "        all_image_info.append(image_info)\n",
    "\n",
    "    # Simpan file CSV per trial\n",
    "    df_trial_detail = pd.DataFrame(all_image_info[-len(unlabeled_dataset):])  # ambil data dari trial ini saja\n",
    "    df_trial_detail.to_csv(f'vit_b_16_finetuned_42labeled_10unlabeled_trial_{trial}_image_clustering.csv', index=False)\n",
    "\n",
    "# Konversi ke DataFrame dan simpan ke CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "mean_values = df_results.select_dtypes(include=np.number).mean()\n",
    "\n",
    "mean_row = pd.DataFrame({\n",
    "    'trial': ['Average'],\n",
    "    'FINCH_ACC': [mean_values['FINCH_ACC']],\n",
    "    'FINCH_NMI': [mean_values['FINCH_NMI']],\n",
    "    'FINCH_Num_Clusters': [mean_values['FINCH_Num_Clusters']],\n",
    "    'KMeans_ACC': [mean_values['KMeans_ACC']],\n",
    "    'KMeans_NMI': [mean_values['KMeans_NMI']],\n",
    "    'KMeans_Num_Clusters': [mean_values['KMeans_Num_Clusters']]\n",
    "})\n",
    "\n",
    "df_results = pd.concat([df_results, mean_row], ignore_index=True)\n",
    "\n",
    "df_results.to_csv('clustering_results_vit_b_16_finetuned_42labeled_10unlabeled_FINCH_KMEANS.csv', index=False)\n",
    "print(\"Results saved to clustering_results_vit_b_16_finetuned_42labeled_10unlabeled_FINCH_KMEANS.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
