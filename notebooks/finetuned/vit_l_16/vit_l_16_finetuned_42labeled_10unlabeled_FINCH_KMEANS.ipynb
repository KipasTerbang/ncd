{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e405366",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_l_16, ViT_L_16_Weights\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.datasets import ImageFolder \n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from finch import FINCH\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    \n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    acc = w[row_ind, col_ind].sum() / y_pred.size\n",
    "    return acc\n",
    "\n",
    "\n",
    "def train_model(model, train_loader, epochs=10):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        for images, labels in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        print(f\"\\nEpoch {epoch+1} | Train Loss: {train_loss:.4f}\")\n",
    "\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Extracting features\"):\n",
    "            images = images.to(device)\n",
    "            feat = model(images)\n",
    "            print(\"Output shape:\", feat.shape)\n",
    "            features.append(feat.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "results = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device Count: {torch.cuda.device_count()}\")\n",
    "print(f\"Current Device: {torch.cuda.current_device()}\")\n",
    "print(f\"Device Name: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"Memory Allocated: {torch.cuda.memory_allocated(0)/1024**2:.2f} MB\")\n",
    "print(f\"Memory Reserved: {torch.cuda.memory_reserved(0)/1024**2:.2f} MB\")\n",
    "print(f\"Max Memory Allocated: {torch.cuda.max_memory_allocated(0)/1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4f9383",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(5):\n",
    "    labeled_transform = transforms.Compose([\n",
    "    transforms.RandAugment(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),])\n",
    "\n",
    "    labeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\42labeled_10unlabeled\\labeled\"\n",
    "\n",
    "    labeled_dataset = ImageFolder(root=labeled_folder, \n",
    "    transform=labeled_transform) \n",
    "    print(f\"Total gambar dalam train dataset: {len(labeled_dataset)} {len(labeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    labeled_loader = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True) \n",
    "    print(f\"Total loader gambar dalam train dataset: {len(labeled_loader)}\")\n",
    "    \n",
    "    model = vit_l_16(weights=ViT_L_16_Weights.IMAGENET1K_V1)\n",
    "\n",
    "    model.heads = torch.nn.Linear(model.heads.head.in_features, len(labeled_dataset.classes))\n",
    "    model = model.to(device)\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "    print(model.encoder.layers[0].mlp[1])\n",
    "    \n",
    "    train_model(model, labeled_loader, epochs=5)\n",
    "\n",
    "    torch.save(model.state_dict(), \"vit_l_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0a3eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trial in range(5):\n",
    "\n",
    "    unlabeled_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "    unlabeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\42labeled_10unlabeled\\unlabeled\"\n",
    "\n",
    "    unlabeled_dataset = ImageFolder(root=unlabeled_folder, transform=unlabeled_transform) \n",
    "    print(f\"Total gambar dalam unlabel dataset: {len(unlabeled_dataset)}  {len(unlabeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Total loader gambar dalam unlabel dataset: {len(unlabeled_loader)}\")\n",
    "    \n",
    "    model = vit_l_16(weights=None)\n",
    "    model.heads = torch.nn.Identity()\n",
    "    model.load_state_dict(torch.load(\"vit_l_16_finetuned_42labeled_10unlabeled_trial_\" + str(trial) + \".pth\"),strict=False)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    unlabeled_features, unlabeled_true_labels = extract_features(unlabeled_loader, model)\n",
    "    \n",
    "    c, num_clust, req_c = FINCH(unlabeled_features, use_ann_above_samples=1000, verbose=True)\n",
    "    finch_clusters = c[:,2]\n",
    "\n",
    "    finch_nmi = normalized_mutual_info_score(unlabeled_true_labels, finch_clusters)\n",
    "    finch_acc = clustering_accuracy(unlabeled_true_labels, finch_clusters)\n",
    "\n",
    "    print(f\"\\nFINCH Clustering Performance:\")\n",
    "    print(f\"Clustering Accuracy (ACC): {finch_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {finch_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(finch_clusters))}\")\n",
    "    \n",
    "    num_clusters = len(np.unique(unlabeled_true_labels))\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans_clusters = kmeans.fit_predict(unlabeled_features)\n",
    "\n",
    "    # ----- Evaluasi -----\n",
    "    kmeans_nmi = normalized_mutual_info_score(unlabeled_true_labels, kmeans_clusters)\n",
    "    kmeans_acc = clustering_accuracy(unlabeled_true_labels, kmeans_clusters)\n",
    "\n",
    "    print(f\"\\nK-Means Clustering Performance: {num_clusters} Clusters\")\n",
    "    print(f\"Clustering Accuracy (ACC): {kmeans_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {kmeans_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(kmeans_clusters))}\")\n",
    "    \n",
    "    # Simpan hasil trial ini\n",
    "    results.append({\n",
    "        'trial': trial,\n",
    "        'FINCH_ACC': finch_acc,\n",
    "        'FINCH_NMI': finch_nmi,\n",
    "        'FINCH_Num_Clusters': len(np.unique(finch_clusters)),\n",
    "        'KMeans_ACC': kmeans_acc,\n",
    "        'KMeans_NMI': kmeans_nmi,\n",
    "        'KMeans_Num_Clusters': len(np.unique(kmeans_clusters)),\n",
    "    })\n",
    "\n",
    "# Konversi ke DataFrame dan simpan ke CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "mean_values = df_results.select_dtypes(include=np.number).mean()\n",
    "\n",
    "mean_row = pd.DataFrame({\n",
    "    'trial': ['Average'],\n",
    "    'FINCH_ACC': [mean_values['FINCH_ACC']],\n",
    "    'FINCH_NMI': [mean_values['FINCH_NMI']],\n",
    "    'FINCH_Num_Clusters': [mean_values['FINCH_Num_Clusters']],\n",
    "    'KMeans_ACC': [mean_values['KMeans_ACC']],\n",
    "    'KMeans_NMI': [mean_values['KMeans_NMI']],\n",
    "    'KMeans_Num_Clusters': [mean_values['KMeans_Num_Clusters']]\n",
    "})\n",
    "\n",
    "df_results = pd.concat([df_results, mean_row], ignore_index=True)\n",
    "\n",
    "df_results.to_csv('clustering_results_vit_l_16_pretrained_42labeled_10unlabeled_FINCH_KMEANS.csv', index=False)\n",
    "print(\"Results saved to clustering_results_vit_l_16_pretrained_42labeled_10unlabeled_FINCH_KMEANS.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
