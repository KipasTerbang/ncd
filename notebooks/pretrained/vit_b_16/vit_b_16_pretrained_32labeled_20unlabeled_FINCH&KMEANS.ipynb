{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705daf4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Total gambar dalam unlabeled dataset: 2000  20\n",
      "Total loader gambar dalam unlabeled dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|          | 1/125 [00:00<00:43,  2.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:23,  5.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:19,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   5%|▍         | 6/125 [00:01<00:20,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▋         | 8/125 [00:01<00:18,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   8%|▊         | 10/125 [00:01<00:17,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|▉         | 12/125 [00:02<00:17,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  11%|█         | 14/125 [00:02<00:17,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  13%|█▎        | 16/125 [00:02<00:17,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▍        | 18/125 [00:03<00:18,  5.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  16%|█▌        | 20/125 [00:03<00:18,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 22/125 [00:03<00:18,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  19%|█▉        | 24/125 [00:04<00:17,  5.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  21%|██        | 26/125 [00:04<00:17,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 28/125 [00:04<00:16,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:05<00:17,  5.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:05<00:16,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:05<00:15,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:06<00:15,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:06<00:15,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:06<00:14,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:07<00:14,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:07<00:13,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:07<00:13,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:08<00:13,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:08<00:12,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:08<00:12,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:09<00:12,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:09<00:11,  5.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:09<00:11,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:10<00:11,  5.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:10<00:10,  5.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:10<00:10,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:11<00:09,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:11<00:09,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:11<00:08,  6.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:12<00:08,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:12<00:08,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:12<00:08,  6.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:13<00:08,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:13<00:07,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:13<00:07,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:13<00:06,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:14<00:06,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:14<00:05,  6.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:14<00:05,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:15<00:05,  6.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:15<00:05,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:15<00:04,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:16<00:04,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:16<00:03,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:16<00:03,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:17<00:03,  6.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:17<00:02,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:17<00:02,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:17<00:02,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:18<00:01,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:18<00:01,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:18<00:01,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:18<00:01,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:19<00:00,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:19<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:19<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:20<00:00,  6.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 379 clusters\n",
      "Partition 1: 83 clusters\n",
      "Partition 2: 24 clusters\n",
      "Partition 3: 7 clusters\n",
      "Partition 4: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.6990\n",
      "Normalized Mutual Information (NMI): 0.8159\n",
      "Number of clusters found: 24\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.6725\n",
      "Normalized Mutual Information (NMI): 0.7768\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabeled dataset: 2000  20\n",
      "Total loader gambar dalam unlabeled dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|          | 1/125 [00:00<00:17,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:17,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:17,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:17,  6.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:19,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:18,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:17,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:16,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:17,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:16,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:16,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:15,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:15,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:04<00:15,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:14,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:05<00:14,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:13,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:13,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:06<00:13,  6.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:06<00:13,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:13,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:12,  6.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:07<00:13,  5.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:13,  5.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:08<00:12,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:08<00:12,  5.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:11,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:09<00:11,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:09<00:11,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:09<00:10,  6.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:10<00:10,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:10<00:10,  5.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:10<00:09,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:11<00:09,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:11<00:09,  5.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:11<00:08,  5.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:12<00:08,  5.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:12<00:07,  6.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:12<00:07,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:13<00:07,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:13<00:06,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:13<00:06,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:13<00:05,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:14<00:05,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:14<00:04,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:14<00:04,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:15<00:04,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:15<00:04,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:15<00:03,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:15<00:03,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:16<00:03,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:16<00:02,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:16<00:02,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:17<00:02,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:17<00:01,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:17<00:01,  7.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:17<00:01,  7.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:18<00:01,  7.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:18<00:00,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:18<00:00,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:19<00:00,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:19<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 373 clusters\n",
      "Partition 1: 79 clusters\n",
      "Partition 2: 21 clusters\n",
      "Partition 3: 6 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.8245\n",
      "Normalized Mutual Information (NMI): 0.8985\n",
      "Number of clusters found: 21\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.7450\n",
      "Normalized Mutual Information (NMI): 0.8313\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabeled dataset: 2000  20\n",
      "Total loader gambar dalam unlabeled dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|          | 1/125 [00:00<00:18,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:17,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:16,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:00<00:16,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:16,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:16,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:16,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:17,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:16,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:16,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:16,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:16,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:16,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:04<00:15,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:15,  6.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:15,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:05<00:14,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:14,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:14,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:06<00:14,  6.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:06<00:13,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:13,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:07<00:12,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:07<00:12,  6.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:12,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:08<00:11,  6.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:08<00:11,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:11,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:09<00:10,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:09<00:10,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:09<00:10,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:09,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:10<00:09,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:10<00:08,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:10<00:08,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:11<00:08,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:11<00:07,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:11<00:07,  6.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:12<00:07,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:12<00:06,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:12<00:06,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:06,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:13<00:06,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:13<00:05,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:13<00:05,  6.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:14<00:05,  6.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:14<00:04,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:14<00:04,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:15<00:04,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:15<00:03,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:15<00:03,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:16<00:03,  6.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:16<00:03,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:16<00:02,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:16<00:02,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:17<00:02,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:17<00:01,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:17<00:01,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:18<00:01,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:18<00:00,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:18<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:18<00:00,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:19<00:00,  6.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 381 clusters\n",
      "Partition 1: 72 clusters\n",
      "Partition 2: 20 clusters\n",
      "Partition 3: 5 clusters\n",
      "Partition 4: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.8175\n",
      "Normalized Mutual Information (NMI): 0.8988\n",
      "Number of clusters found: 20\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.8285\n",
      "Normalized Mutual Information (NMI): 0.8800\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabeled dataset: 2000  20\n",
      "Total loader gambar dalam unlabeled dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|          | 1/125 [00:00<00:17,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:17,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:17,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:16,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:16,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:17,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:16,  6.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:15,  6.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:15,  6.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:15,  6.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:14,  6.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:15,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:14,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:03<00:14,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:14,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:13,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:04<00:13,  6.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:13,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:13,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:05<00:12,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:05<00:12,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:11,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:11,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:06<00:11,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:10,  6.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:07<00:10,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:07<00:10,  6.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:08<00:10,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:08<00:10,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:08<00:09,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:08<00:10,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:09,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:09<00:09,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:09<00:08,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:10<00:08,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:10<00:08,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:10<00:07,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:11<00:07,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:11<00:07,  6.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:11<00:07,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:12<00:06,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:06,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:12<00:05,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:12<00:05,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:13<00:05,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:13<00:05,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:13<00:04,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:14<00:04,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:14<00:04,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:14<00:03,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:15<00:03,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:15<00:03,  6.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:15<00:03,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:15<00:02,  6.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:16<00:02,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:16<00:02,  6.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:16<00:01,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:17<00:01,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:17<00:01,  6.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:17<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:18<00:00,  6.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:18<00:00,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 366 clusters\n",
      "Partition 1: 75 clusters\n",
      "Partition 2: 20 clusters\n",
      "Partition 3: 6 clusters\n",
      "Partition 4: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7375\n",
      "Normalized Mutual Information (NMI): 0.8652\n",
      "Number of clusters found: 20\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.7105\n",
      "Normalized Mutual Information (NMI): 0.8190\n",
      "Number of clusters found: 20\n",
      "Total gambar dalam unlabeled dataset: 2000  20\n",
      "Total loader gambar dalam unlabeled dataset: 125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   1%|          | 1/125 [00:00<00:18,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   2%|▏         | 3/125 [00:00<00:18,  6.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   4%|▍         | 5/125 [00:00<00:17,  6.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   6%|▌         | 7/125 [00:01<00:17,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   7%|▋         | 9/125 [00:01<00:16,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   9%|▉         | 11/125 [00:01<00:16,  6.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  10%|█         | 13/125 [00:01<00:16,  6.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  12%|█▏        | 15/125 [00:02<00:15,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  14%|█▎        | 17/125 [00:02<00:15,  7.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  15%|█▌        | 19/125 [00:02<00:15,  7.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  17%|█▋        | 21/125 [00:03<00:14,  7.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  18%|█▊        | 23/125 [00:03<00:14,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  20%|██        | 25/125 [00:03<00:14,  7.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  22%|██▏       | 27/125 [00:03<00:13,  7.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  23%|██▎       | 29/125 [00:04<00:13,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  25%|██▍       | 31/125 [00:04<00:13,  7.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  26%|██▋       | 33/125 [00:04<00:12,  7.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  28%|██▊       | 35/125 [00:05<00:12,  6.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  30%|██▉       | 37/125 [00:05<00:12,  7.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  31%|███       | 39/125 [00:05<00:12,  7.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  33%|███▎      | 41/125 [00:05<00:11,  7.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  34%|███▍      | 43/125 [00:06<00:11,  7.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  36%|███▌      | 45/125 [00:06<00:11,  7.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  38%|███▊      | 47/125 [00:06<00:11,  7.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  39%|███▉      | 49/125 [00:07<00:11,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  41%|████      | 51/125 [00:07<00:10,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  42%|████▏     | 53/125 [00:07<00:10,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  44%|████▍     | 55/125 [00:07<00:09,  7.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  46%|████▌     | 57/125 [00:08<00:09,  7.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  47%|████▋     | 59/125 [00:08<00:09,  7.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  49%|████▉     | 61/125 [00:08<00:09,  7.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  50%|█████     | 63/125 [00:09<00:08,  6.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  52%|█████▏    | 65/125 [00:09<00:09,  6.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  54%|█████▎    | 67/125 [00:09<00:08,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  55%|█████▌    | 69/125 [00:09<00:08,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  57%|█████▋    | 71/125 [00:10<00:08,  6.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  58%|█████▊    | 73/125 [00:10<00:07,  6.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  60%|██████    | 75/125 [00:10<00:07,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  62%|██████▏   | 77/125 [00:11<00:07,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  63%|██████▎   | 79/125 [00:11<00:07,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  65%|██████▍   | 81/125 [00:11<00:06,  6.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  66%|██████▋   | 83/125 [00:12<00:06,  6.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  68%|██████▊   | 85/125 [00:12<00:05,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  70%|██████▉   | 87/125 [00:12<00:05,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  71%|███████   | 89/125 [00:12<00:05,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  73%|███████▎  | 91/125 [00:13<00:05,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  74%|███████▍  | 93/125 [00:13<00:04,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  76%|███████▌  | 95/125 [00:13<00:04,  6.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  78%|███████▊  | 97/125 [00:14<00:04,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  79%|███████▉  | 99/125 [00:14<00:03,  6.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  81%|████████  | 101/125 [00:14<00:03,  6.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  82%|████████▏ | 103/125 [00:15<00:03,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  84%|████████▍ | 105/125 [00:15<00:02,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  86%|████████▌ | 107/125 [00:15<00:02,  6.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  87%|████████▋ | 109/125 [00:15<00:02,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  89%|████████▉ | 111/125 [00:16<00:02,  6.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  90%|█████████ | 113/125 [00:16<00:01,  6.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  92%|█████████▏| 115/125 [00:16<00:01,  6.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  94%|█████████▎| 117/125 [00:17<00:01,  6.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  95%|█████████▌| 119/125 [00:17<00:00,  6.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  97%|█████████▋| 121/125 [00:17<00:00,  6.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:  98%|█████████▊| 123/125 [00:17<00:00,  6.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Output shape: torch.Size([16, 768])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features: 100%|██████████| 125/125 [00:18<00:00,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([16, 768])\n",
      "Using PyNNDescent to compute 1st-neighbours at this step ...\n",
      "Step PyNNDescent done ...\n",
      "Partition 0: 372 clusters\n",
      "Partition 1: 74 clusters\n",
      "Partition 2: 25 clusters\n",
      "Partition 3: 5 clusters\n",
      "Partition 4: 2 clusters\n",
      "\n",
      "FINCH Clustering Performance:\n",
      "Clustering Accuracy (ACC): 0.7910\n",
      "Normalized Mutual Information (NMI): 0.8648\n",
      "Number of clusters found: 25\n",
      "\n",
      "K-Means Clustering Performance: 20 Clusters\n",
      "Clustering Accuracy (ACC): 0.7425\n",
      "Normalized Mutual Information (NMI): 0.8210\n",
      "Number of clusters found: 20\n",
      "Results saved to clustering_results_vit_b_16_pretrained_32labeled_20unlabeled_FINCH_KMEANS.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import vit_b_16, ViT_B_16_Weights\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision.datasets import ImageFolder \n",
    "import numpy as np\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from tqdm import tqdm\n",
    "from finch import FINCH\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "def clustering_accuracy(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "\n",
    "    D = max(y_pred.max(), y_true.max()) + 1\n",
    "    w = np.zeros((D, D), dtype=np.int64)\n",
    "    \n",
    "    for i in range(y_pred.size):\n",
    "        w[y_pred[i], y_true[i]] += 1\n",
    "\n",
    "    row_ind, col_ind = linear_sum_assignment(w.max() - w)\n",
    "    acc = w[row_ind, col_ind].sum() / y_pred.size\n",
    "    return acc\n",
    "\n",
    "def extract_features(loader, model):\n",
    "    features = []\n",
    "    labels = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, targets in tqdm(loader, desc=\"Extracting features\"):\n",
    "            images = images.to(device)\n",
    "            feat = model(images)\n",
    "            print(\"Output shape:\", feat.shape)\n",
    "            features.append(feat.cpu().numpy())\n",
    "            labels.append(targets.numpy())\n",
    "    return np.concatenate(features), np.concatenate(labels)\n",
    "\n",
    "results = []\n",
    "all_image_info = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "for trial in range(5):\n",
    "\n",
    "    unlabeled_transform = transforms.Compose([ \n",
    "    transforms.ToTensor(), \n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) ])\n",
    "\n",
    "    unlabeled_folder = fr\"C:\\Users\\HP\\novelty\\split_datasets\\trial_{trial}\\32labeled_20unlabeled\\unlabeled\"\n",
    "\n",
    "    unlabeled_dataset = ImageFolder(root=unlabeled_folder, transform=unlabeled_transform) \n",
    "    print(f\"Total gambar dalam unlabeled dataset: {len(unlabeled_dataset)}  {len(unlabeled_dataset.classes)}\")\n",
    "\n",
    "    batch_size = 16\n",
    "\n",
    "    unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=batch_size, shuffle=False)\n",
    "    print(f\"Total loader gambar dalam unlabeled dataset: {len(unlabeled_loader)}\")\n",
    "    \n",
    "    model = vit_b_16(weights=ViT_B_16_Weights.IMAGENET1K_V1)\n",
    "    model.heads = torch.nn.Identity()\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    unlabeled_features, unlabeled_true_labels = extract_features(unlabeled_loader, model)\n",
    "    \n",
    "    \n",
    "    c, num_clust, req_c = FINCH(unlabeled_features, use_ann_above_samples=1000, verbose=True)\n",
    "    finch_clusters = c[:,2]\n",
    "\n",
    "    finch_nmi = normalized_mutual_info_score(unlabeled_true_labels, finch_clusters)\n",
    "    finch_acc = clustering_accuracy(unlabeled_true_labels, finch_clusters)\n",
    "\n",
    "    print(f\"\\nFINCH Clustering Performance:\")\n",
    "    print(f\"Clustering Accuracy (ACC): {finch_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {finch_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(finch_clusters))}\")\n",
    "    \n",
    "    num_clusters = len(np.unique(unlabeled_true_labels))\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
    "    kmeans_clusters = kmeans.fit_predict(unlabeled_features)\n",
    "\n",
    "    # ----- Evaluasi -----\n",
    "    kmeans_nmi = normalized_mutual_info_score(unlabeled_true_labels, kmeans_clusters)\n",
    "    kmeans_acc = clustering_accuracy(unlabeled_true_labels, kmeans_clusters)\n",
    "\n",
    "    print(f\"\\nK-Means Clustering Performance: {num_clusters} Clusters\")\n",
    "    print(f\"Clustering Accuracy (ACC): {kmeans_acc:.4f}\")\n",
    "    print(f\"Normalized Mutual Information (NMI): {kmeans_nmi:.4f}\")\n",
    "    print(f\"Number of clusters found: {len(np.unique(kmeans_clusters))}\")\n",
    "    \n",
    "    # Simpan hasil trial ini\n",
    "    results.append({\n",
    "        'trial': trial,\n",
    "        'FINCH_ACC': finch_acc,\n",
    "        'FINCH_NMI': finch_nmi,\n",
    "        'FINCH_Num_Clusters': len(np.unique(finch_clusters)),\n",
    "        'KMeans_ACC': kmeans_acc,\n",
    "        'KMeans_NMI': kmeans_nmi,\n",
    "        'KMeans_Num_Clusters': len(np.unique(kmeans_clusters)),\n",
    "    })\n",
    "    \n",
    "     # Simpan hasil per gambar\n",
    "    for i in range(len(unlabeled_dataset)):\n",
    "        path, true_label = unlabeled_dataset.samples[i]\n",
    "        image_info = {\n",
    "            'trial': trial,\n",
    "            'image_path': path,\n",
    "            'true_label': true_label,\n",
    "            'finch_cluster': int(finch_clusters[i]),\n",
    "            'kmeans_cluster': int(kmeans_clusters[i])\n",
    "        }\n",
    "        all_image_info.append(image_info)\n",
    "\n",
    "    # Simpan file CSV per trial\n",
    "    df_trial_detail = pd.DataFrame(all_image_info[-len(unlabeled_dataset):])  # ambil data dari trial ini saja\n",
    "    df_trial_detail.to_csv(f'vit_b_16_pretrained_32labeled_20unlabeled_trial_{trial}_image_clustering.csv', index=False)\n",
    "\n",
    "# Konversi ke DataFrame dan simpan ke CSV\n",
    "df_results = pd.DataFrame(results)\n",
    "mean_values = df_results.select_dtypes(include=np.number).mean()\n",
    "\n",
    "mean_row = pd.DataFrame({\n",
    "    'trial': ['Average'],\n",
    "    'FINCH_ACC': [mean_values['FINCH_ACC']],\n",
    "    'FINCH_NMI': [mean_values['FINCH_NMI']],\n",
    "    'FINCH_Num_Clusters': [mean_values['FINCH_Num_Clusters']],\n",
    "    'KMeans_ACC': [mean_values['KMeans_ACC']],\n",
    "    'KMeans_NMI': [mean_values['KMeans_NMI']],\n",
    "    'KMeans_Num_Clusters': [mean_values['KMeans_Num_Clusters']]\n",
    "})\n",
    "\n",
    "df_results = pd.concat([df_results, mean_row], ignore_index=True)\n",
    "\n",
    "df_results.to_csv('clustering_results_vit_b_16_pretrained_32labeled_20unlabeled_FINCH_KMEANS.csv', index=False)\n",
    "print(\"Results saved to clustering_results_vit_b_16_pretrained_32labeled_20unlabeled_FINCH_KMEANS.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
